---
title: "Enhancing Joint Modeling"
format: html
editor: visual
---

## Quarto

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.

## Running Code

When you click the **Render** button a document will be generated that includes both content and the output of embedded code. You can embed code like this:

```{r}
library(EdSurvey)
library(mice)
library(miceadds)
library(naniar)
library(survey)
library(psych)
library(tidyverse)
library(mitools)
library(car)
library(mitml)
```

```{r}
x <- model.matrix(~x1tchapp+x2kage_r+x2povty+p1hig_1+x1prnapp+x1inbcnt
                     +x1attnfs+a1yrstch+a1hghstd+x1pltot+x2clsnss+x2cnflct+x1pltot:x2clsnss, data = new.comp.kndr)
logit.vif <- svydiags::svyvif(k.rep.model, x, w=new.comp.kndr$w12t0)


#using influx and outflux to update imputation model formula 
flux <- flux(dll.atl.kndr)
fluxplot(dll.atl.kndr)

fm1 <- list(cat.atl + x2kage_r + x_chsex_r + x2povty + kndr_par_ed + 
            x1tchapp + x2pltot + x2cnflct + x2prnapp + x2attnfs + 
            x2tchext + a1yrstch + a1yrborn + a1hghstd ~ 1 + (1 | s2_id), 
            x2pubpri + x2locale ~ 1)
#new model removes x2clsnss... redundancy
#inhbtcntrl multicollinearity

#remove high influx, low outflux--> NA dependent on other VARS, but itself is not a useful predictor for imputation

#x2pvoty, parent Ed predicted by other variables
# prelas x2_cnflct, x2_clsnss
```

Kinder Model Building - Edited 10/9 after stats consulting visit (scaled closeness +interaction)

```{r}
comp.kndr$x2clsnss_scaled <- scale(comp.kndr$x2clsnss, scale = F)

comp.model <- svyglm(data=comp.kndr, 
                     formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k
                     +x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                       a1yrstch+a1hghstd+
                       x1pltot+x2cnflct+x1pltot*x2clsnss_scaled,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")


null.k <- svyglm(data=comp.kndr, formula = cat.atl ~ 1,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

k.ch.dem <- svyglm(data=comp.kndr, formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+
                     par.ed.k,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(k.ch.dem)$deviance
AIC(k.ch.dem)
BIC(k.ch.dem, maximal = comp.model)
anova(null.k, k.ch.dem, test="Chisq", method = "LR")# comparing null model to block 1 gets LR for block 1
anova(null.k, k.ch.dem, test="Chisq", method = "Wald")


k.ch.cntrl <- svyglm(data= comp.kndr, formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+
                       par.ed.k+
                       x1tchapp+x1prnapp+x1inbcnt+x1attnfs,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(k.ch.cntrl)$deviance
AIC(k.ch.cntrl)
BIC(k.ch.cntrl, maximal = comp.model)
anova(null.k, k.ch.cntrl) # LR for block 2
anova(null.k, k.ch.cntrl, test="Chisq", method="Wald")
anova(k.ch.dem, k.ch.cntrl, method = "LR") # change in LR


k.tch.cov <- svyglm(data= comp.kndr,formula = cat.atl ~ x1tchapp+x2kage_r+x_chsex_r+
                      x2povty+par.ed.k
                    +x1prnapp+x1inbcnt+x1attnfs+
                      a1yrstch+a1hghstd,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(k.tch.cov)$deviance
AIC(k.tch.cov)
BIC(k.tch.cov, maximal = comp.model)#different maximal specified since I will be removing these terms 
anova(null.k, k.tch.cov)
anova(null.k, k.tch.cov, test="Chisq", method="Wald")
anova(k.ch.cntrl, k.tch.cov, method = "LR") # indicates that including teacher controls does not significantly improve the model 


k.pred <- svyglm(data=comp.kndr,formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k
                 +x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                   a1yrstch #check to see if this matches spreadsheet 10/23... it does
                 +x1pltot+x2clsnss_scaled+x2cnflct,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(k.pred)$deviance
AIC(k.pred)
BIC(k.pred, maximal = full.k)
anova(null.k, k.pred)
anova(null.k, k.pred, method = "Wald", test="Chisq")
anova(k.ch.cntrl, k.pred, method = "LR")

full.k <- svyglm(data=comp.kndr, formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k
                 +x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                   a1yrstch+
                   x1pltot+x2cnflct+x1pltot*x2clsnss_scaled,
  design = k.rep.des, return.replicates=F, family = "quasibinomial") #interaction term does not significantly improve model; but is of scientific interest

summary(full.k)$deviance
AIC(full.k)
BIC(full.k, maximal = full.k)
anova(null.k, full.k)
anova(null.k, full.k, test = "Chisq", method="Wald")
anova(k.pred, full.k, test = "Chisq", method = "LR")

```

Kinder Complete obs - No Sampling weight - No Clustered SE

```{r}

base.k.model <- glm(data = comp.kndr, 
                    formula= cat.atl ~x2kage_r+x_chsex_r+x2povty+par.ed.k
                    +x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                      a1yrstch+
                      x1pltot+x2cnflct+x1pltot*x2clsnss_scaled,
                    family = "binomial")
summary(base.k.model)
exp(coef(base.k.model))
exp(confint(base.k.model))

#adjEd.k.model <- glm(data = comp.kndr, formula= cat.atl ~x2kage_r+x_chsex_r+x2povty
       #             +par.ed.k+x1tchapp+x1prnapp+x1inbcnt+x1attnfs+x1pltot+x2clsnss
         #           +x2cnflct+x1pltot:x2clsnss, 
        #            family = "quasibinomial")

#summary(adjEd.k.model)
#exp(confint(adjEd.k.model))
#condensing ed categories with small obs fixed CI
```

Kinder Sampling Weight + Complete Obs (updated formula w scaled closeness)

```{r}
k.des <- svydesign(ids = ~s2_id, data = comp.kndr, weights = ~w12t0, nest = T)
k.rep.des <- as.svrepdesign(k.des, repweights= "w12t[1-9]+", type = "JK1", combined.weights = T)

wght.model <- svyglm(formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k+
                       x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                       a1yrstch+
                       x1pltot+x2cnflct+x1pltot*x2clsnss_scaled,
  design = k.des, family = "quasibinomial")

k.rep.model <- svyglm(formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k+
                        x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                        a1yrstch+
                        x1pltot+x2cnflct+x1pltot*x2clsnss_scaled,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(wght.model)
exp(coefficients(wght.model))
exp(confint(wght.model))

summary(k.rep.model)
exp(coefficients(k.rep.model))
exp(confint(k.rep.model))
#coefficients are similar... SEs larger for replicate weights.. some p values are different

car::Anova(k.rep.model, type = 3, test = "Chisq")

regTermTest(k.rep.model, ~x_chsex_r)
```

Kinder Comp Obs + SW: Conflict Interaction term

```{r}
comp.kndr$conflict_scaled <- scale(comp.kndr$x2cnflct, scale = F)

k.cnflct.mdl <- svyglm(formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k+
                        x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                        a1yrstch+
                        x1pltot+x2clsnss+x1pltot*conflict_scaled,
  design = k.rep.des, return.replicates=F, family = "quasibinomial")

summary(k.cnflct.mdl)
exp(coefficients(k.cnflct.mdl))
exp(confint(k.cnflct.mdl))
```

First Grade Model Building

```{r}
null <- svyglm(data = wght.comp.fst, formula= fst.cat.atl ~1, design = fst.rep.des ,family = "quasibinomial")

block.1 <- svyglm(data=wght.comp.fst,
                  formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed,
                  design = fst.rep.des, family = "quasibinomial")
AIC(block.1)
BIC(block.1, maximal = fst.comp.model)
anova(null, block.1, method="Wald", test = "Chisq")
anova(null, block.1)
summary(block.1)$deviance

block.2 <- svyglm(data = wght.comp.fst, 
                  formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed+
                  x3tchapp+ x4prnapp + x4inbcnt + x4attnfs,
                       design = fst.rep.des, family = "quasibinomial")
anova(null, block.2, method="Wald", test = "Chisq")
anova(null, block.2)
anova(block.1, block.2)
AIC(block.2)
BIC(block.2, maximal = fst.comp.model)
summary(block.2)$deviance


block.3 <- svyglm(data=wght.comp.fst, 
                  formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed + 
                    x3tchapp+x4prnapp + x4inbcnt + x4attnfs + 
                    a4yrstch + a4hghstd 
                           ,design = fst.rep.des, family = "quasibinomial")
anova(block.2, block.3) # teacher covars are signifcant improvements to model... maybe bc of sample size differences
anova(null, block.3, method = "Wald", test = "Chisq") #specify WALD or LR for different model evals
anova(null, block.3)
AIC(block.3)
BIC(block.3, maximal = fst.comp.model)
summary(block.3)$deviance

block.4 <- svyglm(data=wght.comp.fst,
  formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed 
  +x3tchapp+ x4prnapp + x4inbcnt + x4attnfs + 
    a4yrstch + a4hghstd + 
    frst.prof + x4clsnss + x4cnflct,
                         design = fst.rep.des, family = "quasibinomial")
anova(block.3, block.4)
anova(null, block.4)
anova(null, block.4, method="Wald", test= "Chisq")
AIC(block.4)
BIC(block.4, maximal = fst.comp.model)
summary(block.4)$deviance

anova(block.4, fst.comp.model)#full model already made in chunk below
#addition of interaction term does not significantly improve model but is of scientific interest
anova(null, fst.comp.model)
anova(null, fst.comp.model, method = "Wald", test="Chisq")
AIC(fst.comp.model)
BIC(fst.comp.model, maximal = fst.comp.model)
summary(fst.comp.model)$deviance

svyscoretest(block.3, add.terms = ~factor(frst.prof) , "individual")

psrsq(logit2, method = c("Cox-Snell")) # for psuedo-R sqaured
regTermTest(logit2, ~ridageyr) # for walds chi squared of indv terms 
MKmisc::HLgof.test(fit = fitted(mod_fit_one), obs = training$Class)
#for last model eval method listed in sample table

```

Results: First grade complete Obs - Full Model

left off here... SE for proficiency and new parent ed variables still large 10/7

Visit stats consulting to troubleshoot

Stats consulting solutions - 1) collapse categories 2) scale closeness TO DO 10/10

Editing variable levels (Parent Ed & Proficiency)

```{r}

wght.comp.fst <- na.omit(dll.atl.frst)
wght.comp.fst$fst.par.ed <- temp.comp.fst$fst.par.ed
#dll.atl.frst$x4locale <- droplevels(dll.atl.frst$x4locale)
#new.comp.fst$x4locale <- droplevels(new.comp.fst$x4locale)

#dll.atl.frst$p4hig_1_i <- factor(dll.atl.frst$p4hig_1_i, exclude = NA)
#new.comp.fst$p4hig_1_i <- factor(new.comp.fst$p4hig_1_i, exclude = NA)

#dll.atl.frst$a4yrborn[dll.atl.frst$a4yrborn == "-9: NOT ASCERTAINED"] <- NA
#new.comp.fst$a4yrborn[new.comp.fst$a4yrborn == "-9: NOT ASCERTAINED"] <- NA

#new.comp.fst$a4yrborn <- droplevels(new.comp.fst$a4yrborn)
#dll.atl.frst$a4yrborn <- droplevels(dll.atl.frst$a4yrborn)

#new.comp.fst$a4hghstd <- droplevels(new.comp.fst$a4hghstd)
#dll.atl.frst$a4hghstd <- droplevels(dll.atl.frst$a4hghstd)

table(wght.comp.fst$fst.cat.atl, wght.comp.fst$fst.par.ed)# categories need to be condensed; this df only
table(wght.comp.fst$fst.cat.atl, wght.comp.fst$frst.prof) #same

temp.comp.fst <- comp.fst["frst.prof"]

temp.comp.fst <- temp.comp.fst %>%
  mutate(frst.prof = case_when(
    frst.prof == "In 1st" ~ "After K",
    frst.prof == "After 1st" ~ "After K",
    TRUE ~ as.character(frst.prof)  # Keep other categories unchanged
  ))
temp.comp.fst$frst.prof <- factor(temp.comp.fst$frst.prof,
                                   levels = c("In K", "After K"))
wght.comp.fst$frst.prof <- temp.comp.fst$frst.prof
comp.fst$frst.prof <- temp.comp.fst$frst.prof


## collapsng parent Ed
temp.comp.fst$fst.par.ed <- wght.comp.fst$fst.par.ed

temp.comp.fst <- temp.comp.fst %>%
  mutate(fst.par.ed = case_when(
    fst.par.ed == "HS or equiv" ~ "HS +",
    fst.par.ed == "Beyond HS" ~ "HS +",
    TRUE ~ as.character(fst.par.ed)  # Keep other categories unchanged
  ))
temp.comp.fst$fst.par.ed <- factor(temp.comp.fst$fst.par.ed,
                                   levels = c("Less than HS", "HS +"), ordered=T)
table(temp.comp.fst$fst.par.ed)

comp.fst$fst.par.ed <- temp.comp.fst$fst.par.ed
wght.comp.fst$fst.par.ed <- temp.comp.fst$fst.par.ed
#NO clusererd SE

#other solutions
#collapse categories - factors
# simplify model: less child controls
# firth - perfect prediction (may not be applicable)
#penalized logistic regression

wght.comp.fst$x4clsnss_scaled <- scale(wght.comp.fst$x4clsnss, scale = F)

```

Base model no Sampling Weight No clustered SE

```{r}

#if schools where even dist... using glmer random slopes, multilevel model

bse.fst.mdl <- glm(data= comp.fst, 
                   formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed+
                           x3tchapp + x4prnapp + x4inbcnt + x4attnfs + 
                           a4yrstch + 
                           frst.prof + x4cnflct + frst.prof*scale(x4clsnss, scale = F),
                   family = "quasibinomial") #scaling directly in formula only works for glm function... 
#wrapping scale in svyglm creates object w scaled values, that is NOT in svydesign object 

summary(bse.fst.mdl) #n=418
exp(coefficients(bse.fst.mdl))
exp(confint(bse.fst.mdl))

#interaction between cat and cont... estimate given when one variable =0
#effect of prof when closeness is at mean

```

First grade SW Closeness full model

```{r}
fst.des <- svydesign(ids = ~s4_id, data = wght.comp.fst, weights = ~w4cf4p20, nest = T) # sampling weight cannot have missing values... what to do for imputed data set? will it cause issues if observation # does not match??

fst.rep.des <- as.svrepdesign(fst.des, repweights= "w4cf4p20[1-9]+", type = "JK1", combined.weights = T, return.replicates=F)

fst.wght.mdl <- svyglm(data=wght.comp.fst,
                       formula=fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed + 
                           x3tchapp +x4prnapp + x4inbcnt + x4attnfs + 
                           a4yrstch + 
                           frst.prof + x4cnflct + frst.prof*x4clsnss_scaled,
                       design = fst.des, family = "quasibinomial")
summary(fst.wght.mdl)
exp(coefficients(fst.wght.mdl))
exp(confint(fst.wght.mdl))

#center closeness arouynd mean 
#quasi gives probability changes... switch other models


fst.comp.model <- svyglm(data = wght.comp.fst, 
                         formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed + 
                           x3tchapp +x4prnapp + x4inbcnt + x4attnfs + 
                           a4yrstch + 
                           frst.prof + x4cnflct + frst.prof*x4clsnss_scaled,
                         design = fst.rep.des, family = "quasibinomial")


summary(fst.comp.model)
exp(coefficients(fst.comp.model))
exp(confint(fst.comp.model))
```

First grade SW Conflict

make eng.prog ordered factor and Rerun ALL FIRST GRADE models 10/25

```{r}
wght.comp.fst$cnflct_scaled <- scale(wght.comp.fst$x4cnflct, scale = F)

fst.cnflct.model <- svyglm(data = wght.comp.fst, 
                         formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed + 
                           x3tchapp +x4prnapp + x4inbcnt + x4attnfs + 
                           a4yrstch + 
                           frst.prof + x4clsnss + frst.prof*cnflct_scaled,
                         design = fst.rep.des, family = "quasibinomial")

summary(fst.cnflct.model)
exp(coef(fst.cnflct.model))
exp(confint(fst.cnflct.model))
```

KINDER NEW Approach for Imputation + Complex Survey Design

```{r}
library(mitml)

#new.fst.imp <- mitml::mids2mitml.list(fst.imp)
#fst.comp <- mitmlComplete(new.fst.imp)
#converting already made imputation object does not work must run jomo impute from mitml
dll.atl.kndr$clsnss_scaled <- scale(dll.atl.kndr$x2clsnss, scale = F)
dll.atl.kndr$cnflct_scaled <- scale(dll.atl.kndr$x2cnflct, scale=F)

d <- dll.atl.kndr[ , c("s2_id", "cat.atl", "par.ed.k", "x1pltot", "x2kage_r", 
                     "x_chsex_r", "x2povty", "x2tchapp", "x1tchapp", 
                     "x2clsnss", "x2cnflct", "x1prnapp", "x1inbcnt", 
                     "x1attnfs", "a1yrstch", "w12t0", "clsnss_scaled", "cnflct_scaled")]
d <- as.data.frame(d)
d$s2_id <- as.factor(d$s2_id)

k.type <- c(-2, 1, 1, 1, 1, 
                     1, 1, 1, 1, 
                     1, 1, 1, 1, 
                     1, 1, 0, 1, 1)

kv2.imp <- mitml::jomoImpute(data = d, type = k.type, seed = 805, n.iter=1000, m = 10, n.burn = 1500)
#old convergence syntax only works in mice

plot.mitml(kv2.imp, trace = "all", print = "beta")
summary(kv2.imp)

kinder.full <- mitmlComplete(kv2.imp)
kinder.full <- mitools::imputationList(kinder.full)
#need implist to work with survey packages; so that error does not populate

k.imp.des <- svydesign(ids = ~s2_id, data = kinder.full, weights = ~w12t0, nest = T)
k.rep.imp <- as.svrepdesign(k.imp.des, repweights= "w12t[1-9]+", type = "JK1", combined.weights = T)

#needs to be run 10/23  
k.atl <- with(k.rep.imp, svyglm(formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k+
                        x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                        a1yrstch+
                        x1pltot+x2cnflct+x1pltot*clsnss_scaled, family = "quasibinomial"))
#k.pool.rslt <- MIcombine(k.atl)
#k.pool.rslt <- summary(k.pool.rslt)
k.pool.rslt<- testEstimates(k.atl, extra.pars = F) 
#go with this summary for main parameters 
  #will have to use other approach to obtain odds ratio 

#needs to be created - 10/23
k.atl.cnflct <- with(k.rep.imp, 
                     svyglm(formula = cat.atl ~ x2kage_r+x_chsex_r+x2povty+par.ed.k+
                        x1tchapp+x1prnapp+x1inbcnt+x1attnfs+
                        a1yrstch+
                        x1pltot+x2clsnss+x1pltot*cnflct_scaled, family = "quasibinomial"))
k.pool.cnflct <- testEstimates(k.atl.cnflct) # p values but not stored as df
```

Kinder Pooled Odds Ratio + CI

```{r}

#OR closeness model
k.pool.OR <- MIcombine(k.atl)
k.pool.OR <- summary(k.pool.OR)

# Extract the parameter estimates and confidence intervals for the coefficients
parameter_estimates <- k.pool.OR$results  # Coefficients (log-odds)
lower_bound <- k.pool.OR$`(lower`        # Lower CI for log-odds
upper_bound <- k.pool.OR$`upper)`          # Upper CI for log-odds

# Calculate odds ratios (exp(beta))
odds_ratios <- exp(parameter_estimates)

# Calculate the confidence intervals for odds ratios
odds_ratios_lower_CI <- exp(lower_bound)   # CI lower bound for odds ratios
odds_ratios_upper_CI <- exp(upper_bound)   # CI upper bound for odds ratios

# Combine odds ratios and their CIs into a data frame for better readability
results_with_OR <- data.frame(
  Variable = rownames(k.pool.OR),  # Assuming variable names are stored in the rownames
  OR = odds_ratios,
  Lower_CI_OR = odds_ratios_lower_CI,
  Upper_CI_OR = odds_ratios_upper_CI
)

# Print the results with odds ratios and confidence intervals
print(results_with_OR)


#Conflict OR
k.cnflct.OR <- MIcombine(k.atl.cnflct)
k.cnflct.OR <- summary(k.cnflct.OR)

# Extract the parameter estimates and confidence intervals for the coefficients
parameter_estimates_cnflct <- k.cnflct.OR$results  # Coefficients (log-odds)
lower_bound_cnflct <- k.cnflct.OR$`(lower`         # Lower CI for log-odds
upper_bound_cnflct <- k.cnflct.OR$`upper)`           # Upper CI for log-odds

# Calculate odds ratios (exp(beta))
odds_ratios_cnflct <- exp(parameter_estimates_cnflct)

# Calculate the confidence intervals for odds ratios
odds_ratios_lower_CI_cnflct <- exp(lower_bound_cnflct)   # CI lower bound for odds ratios
odds_ratios_upper_CI_cnflct <- exp(upper_bound_cnflct)   # CI upper bound for odds ratios

# Combine odds ratios and their CIs into a data frame for better readability
results_with_OR_cnflct <- data.frame(
  Variable = rownames(k.cnflct.OR),  # Assuming variable names are stored in the rownames
  OR = odds_ratios_cnflct,
  Lower_CI_OR = odds_ratios_lower_CI_cnflct,
  Upper_CI_OR = odds_ratios_upper_CI_cnflct
)

# Print the results with odds ratios and confidence intervals
print(results_with_OR_cnflct)
```

First Grade Results w IMPUTATION - Clustered SE, No sampling weight

RE run imputation with scaled variables, try n.iter 5000? 10/25

```{r}
bse.fst.mdl <- glm(data= comp.fst, 
                   formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed+
                           x3tchapp + x4prnapp + x4inbcnt + x4attnfs + 
                           a4yrstch + 
                           frst.prof + x4cnflct + frst.prof*scale(x4clsnss, scale = F),
                   family = "quasibinomial")


df <- dll.atl.frst[,c("s4_id","x4age", "x_chsex_r", "x4povty_i", "fst.par.ed", 
                      "x3tchapp", "x4tchapp","x4clsnss", "x4cnflct", "x4prnapp",
                      "x4attnfs", "x4inbcnt", "a4yrstch", "fst.cat.atl", "frst.prof")]
df <- as.data.frame(df)
df$s4_id <- factor(df$s4_id)
df$frst.prof <- factor(df$frst.prof, levels = c("In K", "In 1st", "After 1st"), ordered = T)=
df$clsnss_scaled <- scale(df$x4clsnss, scale = F)
df$cncflct_scaled <- scale(df$x4cnflct, scale = F)

type <- c(-2, 1, 1, 1, 1, 
                      1, 1, 1,1, 1,
                      1, 1, 1, 1, 3, 1, 1)
fst.v2.imp <- mitml::jomoImpute(data = df, type = type, seed = 805, n.iter=5000, m = 10, n.burn = 10000)
#jumped from 5 burn, 3 n.iter to 5n.iter and 10 burn
#run diagnositics and model fitting 10/24

plot.mitml(fst.v2.imp)
summary(fst.v2.imp)

```

ReRUN results with scaled variables

```{r}
frst.full <- mitmlComplete(fst.v2.imp)
frst.full <- mitools::imputationList(frst.full)

fst.imp.des <- svydesign(ids = ~s4_id, data = frst.full)

frst.mdl <- with(fst.imp.des, svyglm(
  formula = fst.cat.atl ~ x4age + x_chsex_r + x4povty_i+ fst.par.ed + 
    x3tchapp + x4prnapp + x4inbcnt + x4attnfs + 
    a4yrstch + 
    frst.prof + x4cnflct + frst.prof*x4clsnss, family = "quasibinomial"))

fst.pool.rslt <- testEstimates(frst.mdl) #has p values

fst.pool.OR <- MIcombine(frst.mdl)
fst.pool.OR <- summary(fst.pool.OR) #has lower and upper limit of pooled point estimate
```

```{r}
log_odds <- fst.pool.OR$results  # pooled log-odds estimates
lower_log_odds <- fst.pool.OR$`(lower`  # lower bounds of CI on log-odds scale
upper_log_odds <- fst.pool.OR$`upper)`  # upper bounds of CI on log-odds scale

# 2. Exponentiate to get the odds ratio and the CI for the odds ratio
odds_ratios <- exp(log_odds)  # odds ratio from log-odds
ci_lower <- exp(lower_log_odds)  # lower bound of the odds ratio CI
ci_upper <- exp(upper_log_odds)  # upper bound of the odds ratio CI

# 3. Create a data frame to present results clearly
odds_ratios_df <- data.frame(
  Predictor = rownames(fst.pool.OR),
  Odds_Ratio = odds_ratios,
  CI_Lower = ci_lower,
  CI_Upper = ci_upper
)

# View the odds ratios and confidence intervals
print(odds_ratios_df)
```
